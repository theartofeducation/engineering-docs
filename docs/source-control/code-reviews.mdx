---
id: code-reviews
slug: /source-control/code-reviews
title: Code Reviews
---

Code reviews are an important part of the <abbr title="Software Development Life Cycle">SDLC</abbr> and the production and delivery of quality code; they are a critical part of the process of introducing both new code and/or changes to existing code into the codebase of a project. Code reviews serve several purposes:

* Ensure consistent style and standards.
* Help find possible issues before they are released into the wild.
* Help to provide suggestions for security, optimization, best practices, etc.
* Help with knowledge transfer amongst the team (we can all learn a lot from a code review).

This document provides an overview for how we practice code reviews at The Art of Education University (AOEU).

## Practice empathy, code is personal

Whether you've ever thought into it this much, or whether you want to admit it or not, code reviews are not just logical exercises, they're personal too. All code at some level or other is the product of a human being (yes, even generated code), and it's important to remember that when reviewing it, _and especially_ when providing feedback on it. Humans are emotional creatures, and all coders, to at least some degree, take a certain amount of pride in the code that they write. It is a reflection of each individuals personal knowledge, skill and experience level, and most consider the quality of their code to be a personal reflection on them as unique individuals.

For many developers, it can be a daunting and sometimes even frightening thing, to submit a pull request (PR) for code review knowing that it's going to be reviewed and critiqued. This is why it's important for us all to remember to review code and provide feedback on it with empathy for the author, and to provide [not only critical, but also positive feedback as well](https://sparkbox.com/foundry/stop_giving_depressing_code_reviews).

### Be objective (both ways)

Regardless of your role in a code review, whether you're the reviewer, or the author of the code, it's important to do your best to try to be as objective about your role in this process as possible. This point may seem obvious, but it feels worth saying it anyway. If you're the reviewer, keep your feedback about the code, and not the author. Be direct, provide as much detail as is practical and possible in your feedback (remember it can often be as helpful to include the _why_ as it is the _what_), and above all else, _be nice about it_.

If you're the author of the code, and receive critique, don't take it personally. We're all just trying to do our job and deliver the best product possible within the constraints in which it is being delivered. Take feedback at face value, and use it to learn and improve your code and your craft.

## Good PRs make code reviews easier

In order to be able to effectively review the code in a PR, it's critical for the reviewer(s) to have a clear understanding of what the _intent_ of the changes being proposed are. For our development team at AOEU, _at a **bare minimum**_, a PR should include **a meaningful title**, and **a link to the issue/task/card in our project management system** ([Clubhouse](https://app.clubhouse.io/aoeu-se)) that is driving the change<super>*</super>. This should be the bare minimum for all of our code reviews. Yes, words can be hard, but its worth the time and effort to put some thought into a meaningful and descriptive title for your PRs.

Beyond that, its up to the author of the PR to determine how much additional information a PR should have. Some definitely require more than others. Screen captures, and even animated gifs or videos can often be useful in providing context for the problem the changes in the PR are attempting to fix. Use your best judgment, but know that the more context you can provide, the easier it will be for reviewers to provide meaningful and useful feedback. Sparkbox has a couple of excellent articles with some great information on what makes for a good pull request: [Creating Good Pull Requests](https://sparkbox.com/foundry/creating_good_pull_requests), and [GitHub Pull Requests for Everyone](https://sparkbox.com/foundry/github_pull_requests_for_everyone). Both should be considered strongly recommended reading.

:::note
**<super>*</super>** It is possible, but should be _a rare exception_, that there is no card in our project management system driving a proposed change to code. It happens, but should definitely not happen very often.
:::

## Better, unambiguous feedback with Severity Level Identifiers (SLIs)

The fine development team at Netlify shared [an excellent article that they wrote about how they have improved their internal code review process through the use of what they call "Feedback Ladders."](https://www.netlify.com/blog/2020/03/05/feedback-ladders-how-we-encode-code-reviews-at-netlify/) We really liked this article and the approach they've taken, and have decided to use it for inspiration and adopt a similar approach to our own internal code review process. Similar to feedback ladders, we are adopting a system of identifiers that help qualify the severity level of the feedback, and associating each severity level with a quickly and easily identifiable emoji that represents the severity level of the feedback.

This system of identifiers can help improve our code review process by removing some of the ambiguity in elements of feedback in a code review. We use GitHub PRs as the basis for our code review process, and for the most part, the exchange of information among team members in a PR is asynchronous, disconnected and almost entirely via text-based communication. Text based communication can be challenging, as it lacks the nuances of verbal and face-to-face communication such as body language and voice inflection, which can often make the intent or tone of a comment or statement much clearer than if the same were communicated simply via text. As a result, it can often be unclear as to whether a piece of feedback on a PR is severe enough to block the PR from approval, or is intended more as an initiation of an exchange or deeper conversation about an issue.

To help remove some of this ambiguity, we prefer that all elements of feedback on a PR be prefixed with one of the following severity level identifiers, to help communicate to the author the intended severity level of the feedback.

:::note
This list is inteded to be used as a reference for all involved in code reviews at AOEU as the basis for understanding the severity level of comments and feedback left on PRs, and their associated meaning and intent.
:::

### Severity Level Identifier List

The following is a list of all of our officially documented Severity Level Identifiers, including the emoji that should be used to prefix the comment, along with the GitHub short code that can be used to render the emoji, and a description of what it means and how/when the issue should be addressed by the author.

* üö® `:rotating_light:` - This is a **blocking issue**, and must be corrected before the PR will be approved. Comments with this SLI should always include a recommendation for what and how to correct the issue.
* ü™≤ or üêû `:beetle:` or `:bug:` - This is a **blocking issue**, and identifies a comment or feedback relative to a bug or defect that was found with the code.
* ‚ö†Ô∏è `:warning:` - This is a **non-blocking issue**, but will require documented, follow-up action in the future. Comments/feedback with this SLI will most often require the addition of a `TODO:` comment in the code, that includes an accompanying link to an issue in our project management system, i.e. `TODO: CH12345 - This needs to be better`.
* üé® or üíÖüèº `:art:` or `:nail_care:` - This is a stylistic issue with the code, and in the vast majority of cases should be **non-blocking**. Stylistic issues with the code should be discussed rarely during code reviews, as they should most often be taken care of before the code ever gets into the review process by our linters, and our coding standards ([JavaScript/React](/pages/coding-standards/javascript-react), [Go](/pages/coding-standards/go), and [Python](/pages/coding-standards/python)). These feedback issues can often result in discussion or back-and-forth that can result in a decision, that could (should?) result in a change to our linters or coding standards to help avoid similar discussions in the future. When that is the case, it should result in an actionable card/task in our project management system.
* ü§î or ‚ùì `:thinking:` or `:question:` - This should be used for questions or requests for clarification. This can sometimes be blocking, depending on the nature of the question and scenario, but typically these are non-blocking, and should be used for help in learning, and just generally understanding the nature or intent of the code.
* In keeping with efforts to help keep our code reviews positive, we also strongly recommend the use of the following SLIs to identify encouraging or positive feedback. Any comments/feedback with any of the following SLIs should never be blocking.
  * ‚ú® `:sparkles:`
  * üí• `:boom:`
  * üëçüèº `:thumbsup:`
  * üí™üèº `:muscle:`
  * üòç `:heart_eyes:`

## Code Review Approval

All of our GitHub repositories should be configured to support this (to the extent possible), but even when not, our recommended rule for Code Review / PR approval is that a PR should only be merged under the following conditions:

* **Approved by QA** - This means that the code being reviewed has been reviewed, tested and approved by QA. This most commonly is identified by the associated card being moved to the "QA Done" column on the board in our project management system.
* **2 Approved Developer Reviews** - The code has been reviewed and approved by two developer peers.
* **All configured CI tasks pass** - Most (if not all) of our repositories should be setup and configured to run GitHub actions to perform certain Continous Integration (CI) tasks (perform linting, run unit tests, automated regression tests, etc). All configured CI tasks for the project must pass before the PR can be merged.
